{
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d84115f-875a-4337-aa66-1ca9665d9a11",
   "metadata": {
    "collapsed": false,
    "name": "overview_md"
   },
   "source": "# Time Series Analytics with Pricing Data on Snowflake\n\nThis solution demonstrates several advanced time series features using FactSet Tick Data on Snowflake. You will learn to leverage powerful SQL functions such as TIME_SLICE, ASOF JOIN, and RANGE BETWEEN to gain deeper insights into time series trade data.\n\nWe're using `tick_history`, available through the Snowflake Marketplace, to gather trading information and have generated synthetic data for closing prices based on that. The `closing_prices` table was created as part of the setup and is available in the `raw` schema.\n\nPlease import below packages to get started:\n\n- matplotlib=3.8.0\n- seaborn=0.13.2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3775908f-ca36-4846-8f38-5adca39217f2",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "imports"
   },
   "outputs": [],
   "source": "# Import python packages\nimport streamlit as st\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# We can also use Snowpark for our analyses!\nfrom snowflake.snowpark.context import get_active_session\nsession = get_active_session()\n\n# Add a query tag to the session. This helps with debugging and performance monitoring.\nsession.query_tag = {\"origin\":\"sf_sit\", \"name\":\"time_series_analysis\", \"version\":{\"major\":1, \"minor\":0}}"
  },
  {
   "cell_type": "markdown",
   "id": "e527fb76-8073-43b6-8641-ee2802772e24",
   "metadata": {
    "collapsed": false,
    "name": "preview_md"
   },
   "source": "#### Preview Data\nWe will be using FactSet Tick History data in this notebook. The data includes access high quality tick data sourced from FactSet’s real-time consolidated feed. In this notebook, we will focus on trade data from META. \n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e62734-e85d-4af7-8408-e3b995fceb02",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "sql",
    "name": "preview"
   },
   "outputs": [],
   "source": [
    "SELECT TOP 100 * \n",
    "FROM tick_history.public.th_sf_mktplace\n",
    "WHERE ticker='META' \n",
    "AND date =20221025\n",
    "AND msg_type = 0 -- trade messages\n",
    "AND security_type = 1; -- equity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8371e65e-b26d-4587-b9da-0ae22b900b2a",
   "metadata": {
    "collapsed": false,
    "name": "meta_trades_md"
   },
   "source": "We'll begin by formatting the data and filtering it for the META ticker, which we will use for future queries. The data from FactSet stores the date and time as integers, so we need to convert these into a proper timestamp format. This involves creating a trade_timestamp by extracting and reformatting the year, month, day, hour, minute, second, and nanoseconds from the integer fields. "
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64556518-34d2-47ad-96fb-d0da7f54a1c2",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "sql",
    "name": "meta_trades"
   },
   "outputs": [],
   "source": "SELECT \n    TIMESTAMP_FROM_PARTS(\n        SUBSTR(date, 0, 4), -- year\n        SUBSTR(date, 5, 2), -- month\n        SUBSTR(date, 7, 2), -- day \n        SUBSTR(LPAD(time, 9, 0), 0, 2), -- hour\n        SUBSTR(LPAD(time, 9, 0), 3, 2), -- minute\n        SUBSTR(LPAD(time, 9, 0), 5, 2), -- second\n        RPAD(SUBSTR(LPAD(time, 9, 0), 7, 3), 9, 0) -- nanoseconds\n    ) AS trade_timestamp,\n    ticker,\n    last_price,\n    last_vol\nFROM tick_history.public.th_sf_mktplace\nWHERE ticker = 'META'\nAND msg_type=0\nAND security_type = 1;"
  },
  {
   "cell_type": "markdown",
   "id": "3859fd31-d350-4057-a501-2d1d5cc2c476",
   "metadata": {
    "collapsed": false,
    "name": "prevailing_price_md"
   },
   "source": "## Use Case 1: Prevailing Price\n\nA common operation in FinServ is calculating the most recent price at which a security or asset was traded. This is a straightforward method and is often used in real-time trading environments. To do so for META, it can be done using simple SQL as follows: "
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7232b0b0-e7be-47e6-a18c-15685c724f67",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "sql",
    "name": "prevailing_price"
   },
   "outputs": [],
   "source": "SELECT *\nFROM {{meta_trades}}\nWHERE trade_timestamp <= '2022-10-10 12:00:00'\nORDER BY trade_timestamp DESC\nLIMIT 1;"
  },
  {
   "cell_type": "markdown",
   "id": "dd0e12c4-5718-4f24-a72b-b888a4203fad",
   "metadata": {
    "collapsed": false,
    "name": "time_slice_md"
   },
   "source": "## Use Case 2: Trading Performance Tracking using TIME_SLICE\nInvestors and analysts often need to track the performance of a stock over a period of time for identifying trends such as increases or decreases in average price and trading volume before making purchase decisions. This can be easily done using the [TIME_SLICE](https://docs.snowflake.com/en/sql-reference/functions/time_slice) function in Snowflake. \n\nNote: The `TIME_SLICE` function in Snowflake segments timestamps into consistent intervals, like hours, days, or weeks, based on a chosen time unit. It returns the start or end of each interval, facilitating the aggregation of data within these defined time periods"
  },
  {
   "cell_type": "markdown",
   "id": "fe26fe38-75c8-4da3-ae4f-936bc9737655",
   "metadata": {
    "collapsed": false,
    "name": "time_slice_2_md"
   },
   "source": "#### Using TIME_SLICE\nWe will now use [TIME_SLICE](https://docs.snowflake.com/en/sql-reference/functions/time_slice) to get the average weekly trade price and total volume. Snowflake Notebooks allow you to [reference the results](https://docs.snowflake.com/en/user-guide/ui-snowsight/notebooks-develop-run#reference-cells-and-variables-in-sf-notebooks) of other cell queries using Jinja syntax."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d50cbf4-0c8d-4950-86cb-114990437ac9",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "sql",
    "name": "weekly_data"
   },
   "outputs": [],
   "source": [
    "SELECT \n",
    "    TIME_SLICE(trade_timestamp, 1, 'WEEK', 'START') AS week_starting,\n",
    "    AVG(last_price) AS average_price,\n",
    "    SUM(last_vol) AS total_volume\n",
    "FROM {{meta_trades}}\n",
    "WHERE ticker='META'\n",
    "GROUP BY week_starting\n",
    "ORDER BY week_starting;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5c3745-dedd-4c60-8d22-7c63e82c4048",
   "metadata": {
    "collapsed": false,
    "name": "plot_slice_md"
   },
   "source": "We can use Streamlit plots directly in our notebook to do a quick plot of average weekly price."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "babb3df2-574e-4567-98d5-4c979e90c178",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "plot_weekly_slice"
   },
   "outputs": [],
   "source": [
    "st.line_chart(weekly_data, x=\"WEEK_STARTING\", y=\"AVERAGE_PRICE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff73ca77-446d-4ee3-8685-593b8bdf9525",
   "metadata": {
    "name": "findings_weekly_slice_md",
    "collapsed": false
   },
   "source": "The plot visualizes the average weekly closing price for the META ticker over time. Each point on the line chart represents the average price of META at the start of each week, allowing you to observe trends and fluctuations in the stock's performance.\n\nSimilarly, analysts can perform Long-Term Performance Tracking by using TIME_SLICE using the YEAR, QUARTER, MONTH, WEEK etc for identifying trends over longer periods."
  },
  {
   "cell_type": "markdown",
   "id": "a6bb1ac9-be35-4157-b902-9971468c6e9d",
   "metadata": {
    "collapsed": false,
    "name": "month_slice_md"
   },
   "source": "#### Slice by Month\n\nLet's find average montly price and total volume."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb63ecba-4fdd-429e-99c5-d0f4e82c4336",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "sql",
    "name": "month_slice"
   },
   "outputs": [],
   "source": [
    "SELECT \n",
    "    TIME_SLICE(trade_timestamp, 1, 'MONTH', 'START') AS month_starting,\n",
    "    AVG(last_price) AS average_price,\n",
    "    SUM(last_vol) AS total_volume\n",
    "FROM {{meta_trades}}\n",
    "WHERE ticker='META'\n",
    "GROUP BY month_starting\n",
    "ORDER BY month_starting;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1b63e1-f3f7-420e-9a07-151fd6f0f1a5",
   "metadata": {
    "collapsed": false,
    "name": "hour_slice_md"
   },
   "source": "#### Slice by Hour\n\nLet's now slice by hour"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603b4913-63cc-46d7-9213-39369877f1d3",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "sql",
    "name": "hour_slice"
   },
   "outputs": [],
   "source": [
    "SELECT \n",
    "    TIME_SLICE(trade_timestamp, 1, 'HOUR', 'START') AS hour_starting,\n",
    "    AVG(last_price) AS average_price,\n",
    "    SUM(last_vol) AS total_volume\n",
    "FROM {{meta_trades}}\n",
    "WHERE DATE(trade_timestamp) = '2022-09-19'\n",
    "AND ticker='META'\n",
    "GROUP BY hour_starting\n",
    "ORDER BY hour_starting;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a337bbd3-79c1-41b1-8bc0-3de181125286",
   "metadata": {
    "collapsed": false,
    "name": "transaction_cost_md"
   },
   "source": "## Use Case 3: Transaction Cost Analysis using ASOF JOIN\n\nAnalysts often want to determine how closely the trade prices align with the closing prices for trade quality analysis or get insight into the market impact of trades, showing whether trades are being executed at prices that significantly differ from the last known closing price, which might suggest market movements or anomalies.\n\nWe will use an [ASOF JOIN](https://docs.snowflake.com/en/sql-reference/constructs/asof-join) to join our trade data with closing price data, which we have stored in `closing_prices` table. The query calculates the price impact of each trade by comparing the trade price with the most recent closing price available at or before the time of the trade. "
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddea28af-5d36-42c3-9c14-af25b181b804",
   "metadata": {
    "collapsed": false,
    "language": "sql",
    "name": "meta_closing_prices"
   },
   "outputs": [],
   "source": [
    "SELECT \n",
    "    TIMESTAMP_FROM_PARTS(\n",
    "        SUBSTR(date, 0, 4), -- year\n",
    "        SUBSTR(date, 5, 2), -- month\n",
    "        SUBSTR(date, 7, 2), -- day \n",
    "        SUBSTR(LPAD(time, 9, 0), 0, 2), -- hour\n",
    "        SUBSTR(LPAD(time, 9, 0), 3, 2), -- minute\n",
    "        SUBSTR(LPAD(time, 9, 0), 5, 2), -- second\n",
    "        RPAD(SUBSTR(LPAD(time, 9, 0), 7, 3), 9, 0) -- nanoseconds\n",
    "    ) AS timestamp,\n",
    "    ticker,\n",
    "    closing_price\n",
    "FROM raw.closing_prices\n",
    "WHERE ticker = 'META';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f174d2c4-56a9-4455-a130-a241d58bebee",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "sql",
    "name": "transaction_cost"
   },
   "outputs": [],
   "source": [
    "SELECT\n",
    "    t1.ticker,\n",
    "    t1.trade_timestamp,\n",
    "    t1.last_price AS trade_price,\n",
    "    t2.closing_price,\n",
    "    trade_price - t2.closing_price AS price_impact,\n",
    "    t1.last_vol\n",
    "FROM \n",
    "     {{meta_trades}} t1\n",
    "ASOF JOIN \n",
    "     {{meta_closing_prices}} t2\n",
    "MATCH_CONDITION \n",
    "    (t1.trade_timestamp <= t2.timestamp)\n",
    "ON \n",
    "    t1.ticker = t2.ticker\n",
    "ORDER BY \n",
    "    t1.ticker,\n",
    "    t1.trade_timestamp;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dce6261-6bf6-45f0-ae09-5eecdc53bc40",
   "metadata": {
    "collapsed": false,
    "name": "daily_sampling_md"
   },
   "source": "Now, let's do a daily summary analysis of trading data, focusing on key metrics like average trade price, average closing price, price impact, cumulative price impact, and total trading volume."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ca6423-a1c2-4a73-9b32-17ebafbbb815",
   "metadata": {
    "collapsed": false,
    "language": "sql",
    "name": "transaction_cost_daily"
   },
   "outputs": [],
   "source": [
    "SELECT \n",
    "    TIME_SLICE(trade_timestamp, 1, 'DAY', 'START') AS trade_date,\n",
    "    AVG(trade_price) AS trade_price,\n",
    "    AVG(closing_price) AS closing_price,\n",
    "    AVG(price_impact) AS price_impact,\n",
    "    SUM(price_impact) AS cumulative_price_impact,\n",
    "    SUM(last_vol) AS total_volume\n",
    "FROM {{transaction_cost}}\n",
    "GROUP BY trade_date\n",
    "ORDER BY trade_date;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9476d5c5-eaef-4286-8132-abe153d23dff",
   "metadata": {
    "collapsed": false,
    "name": "to_pandas_md"
   },
   "source": [
    "We can also reference SQL cells in Python within the same notebook. Let's convert the daily sampled data to pandas for plotting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e70d73e-2f86-45b9-9a8c-1b5276fb5303",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "to_pandas"
   },
   "outputs": [],
   "source": "df = transaction_cost_daily.to_pandas()"
  },
  {
   "cell_type": "markdown",
   "id": "b6e325d8-e294-49d3-8edb-8cad3d6d95cc",
   "metadata": {
    "collapsed": false,
    "name": "price_comp_md"
   },
   "source": "#### Trade Prices vs. Market Prices Over Time"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396465b0-0893-4aa8-b362-77f8271d531f",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "price_comp"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 7))\n",
    "sns.lineplot(x='TRADE_DATE', y='TRADE_PRICE', data=df, label='Trade Price', color='blue')\n",
    "sns.lineplot(x='TRADE_DATE', y='CLOSING_PRICE', data=df, label='Market Price', color='red', linestyle='--')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Price')\n",
    "plt.title('Trade Prices vs. Market Prices Over Time')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df27afd-19b4-4f03-91ed-87694090e202",
   "metadata": {
    "name": "findings_price_comp_md",
    "collapsed": false
   },
   "source": "\nThis plot compares trade prices and market (closing) prices for a given dataset over time. The blue line represents the trade prices, while the red dashed line shows the market (closing) prices. This plot highlight the relationship and differences between the trade and closing prices across the selected time period."
  },
  {
   "cell_type": "markdown",
   "id": "f3b68256-622f-4273-83a7-d935f9fe4d48",
   "metadata": {
    "collapsed": false,
    "name": "price_impact_md"
   },
   "source": "#### Price Impact of Trades\nUnderstanding the price impact helps in evaluating market efficiency. If trades consistently move prices significantly, it might indicate lower liquidity or higher volatility.\nFor traders, knowing the price impact helps in planning their trades to minimize market impact, especially for large orders. They might break up large orders or trade at specific times to reduce impact."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85eee5b5-9189-4934-8081-92d125af7e2c",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "price_impact"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 7))\n",
    "sns.scatterplot(x='TRADE_DATE', y='PRICE_IMPACT', data=df, alpha=0.5, color='purple')\n",
    "plt.axhline(0, color='black', linestyle='--')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Price Impact')\n",
    "plt.title('Price Impact of Trades Over Time')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bfcd609-fb7e-406e-95dd-1f876993a053",
   "metadata": {
    "name": "findings_price_imp_md",
    "collapsed": false
   },
   "source": "This scatter plot shows the price impact of trades over time. Each point represents the price impact of a trade, with the plot helping to identify trends and patterns in how trades influenced market prices throughout the observed period. The horizontal reference line highlights whether the impact was positive or negative. Positive price impact might indicate bullish sentiment or aggressive buying. Negative price impact might indicate bearish sentiment or aggressive selling.\n\nThe distribution of META stock values shows varying densities, indicating that the price impact of trades fluctuates over time. High-density areas reflect periods when many trades clustered around similar price impacts, which could be due to high trading activity or specific market conditions affecting the stock. Low-density areas, conversely, suggest fewer trades or a wider range of price impacts. Analyzing these patterns can provide insights into periods of significant market influence or volatility, helping traders to understand how different trading conditions affect price impact."
  },
  {
   "cell_type": "markdown",
   "id": "dfed4281-f2f3-4ed7-b5c8-f8095117921f",
   "metadata": {
    "collapsed": false,
    "name": "price_volume_md"
   },
   "source": "#### Volume vs. Price Impact"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbdc4e38-d675-48e4-8b16-21faee93dfaf",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "price_volume"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 7))\n",
    "sns.scatterplot(x='TOTAL_VOLUME', y='PRICE_IMPACT', data=df, alpha=0.5, color='green')\n",
    "plt.xlabel('Volume')\n",
    "plt.ylabel('Price Impact')\n",
    "plt.title('Trade Volume vs. Price Impact')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa47ab2-f43d-4b80-a3ad-52fc40bd7a43",
   "metadata": {
    "name": "findings_price_vol_md",
    "collapsed": false
   },
   "source": "\nThis scatter plot depicts the relationship between trade volume and price impact. Each point represents a trade, with its position indicating how the trade volume correlates with the price impact. \n\nMost trades in the plot have volumes below 0.5 and price impacts ranging from -3 to 2. This distribution indicates that smaller trade volumes are common and their impact on price varies within a moderate range. It suggests that, for the data observed, the price impact remains relatively contained despite the low trade volumes, potentially reflecting a market where such trades have minimal influence on price movements."
  },
  {
   "cell_type": "markdown",
   "id": "b42bbf8c-d7b9-4b12-8167-073e024f01cb",
   "metadata": {
    "name": "distribution_md",
    "collapsed": false
   },
   "source": "#### Distribution of Price Impacts"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3255fee4-3e76-4fdd-b0fe-3568eade929f",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "distribution"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 7))\n",
    "sns.histplot(df['PRICE_IMPACT'], bins=50, color='orange', kde=True)\n",
    "plt.xlabel('Price Impact')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Price Impacts')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f172619-2e3b-40d1-9db3-d4df7d58d96d",
   "metadata": {
    "name": "findings_distribution",
    "collapsed": false
   },
   "source": "\nThis histogram displays the distribution of price impacts across trades. The plot uses 50 bins to show how frequently different price impact values occur, with the orange bars representing the frequency of each range and the KDE (Kernel Density Estimate) curve providing a smoothed representation of the distribution.\n\nThe histogram and KDE reveal a bell-shaped curve, indicating that price impacts are symmetrically distributed around a central value, suggesting a normal distribution."
  },
  {
   "cell_type": "markdown",
   "id": "8bc50630-9cd5-4f12-9eec-504b64a68f8d",
   "metadata": {
    "name": "cumulative_md",
    "collapsed": false
   },
   "source": "#### Cumulative Price Impact"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442949f6-6a58-414d-9a5f-5dd47a444d37",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "cumulative"
   },
   "outputs": [],
   "source": [
    "st.line_chart(df.set_index('TRADE_DATE')['CUMULATIVE_PRICE_IMPACT'], use_container_width=True, color = [\"#FF0000\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23fbaaa4-4f3f-42d1-b400-1755d554a0aa",
   "metadata": {
    "name": "findings_cumulative",
    "collapsed": false
   },
   "source": "This line chart shows how the cumulative price impact of trades changes over time. The red line indicates the trend in total price impact, revealing how it accumulates throughout the trading period."
  },
  {
   "cell_type": "markdown",
   "id": "a7657296-93e9-452f-8259-e3a302fbdbf5",
   "metadata": {
    "name": "Slippage_md",
    "collapsed": false
   },
   "source": "### Slippage Calculation\nAs an alternative to using the closing price for our benchmark value, we can use the best bid offer ([BBO](https://databento.com/docs/examples/algo-trading/execution-slippage/overview)) price in addition to specifying a time window around our trade time. "
  },
  {
   "cell_type": "markdown",
   "id": "690c929e-fe1b-4311-9fb9-aa395bba2e54",
   "metadata": {
    "name": "mytrades_md",
    "collapsed": false
   },
   "source": "First, let’s specify a subset of trades we want to analyze. `mytrades` table has already been created as part of the set up."
  },
  {
   "cell_type": "code",
   "id": "57b69267-046a-4113-b1c9-18481ffbbad1",
   "metadata": {
    "language": "sql",
    "name": "mytrades",
    "collapsed": false
   },
   "outputs": [],
   "source": "SELECT * \nFROM raw.mytrades\nWHERE ticker = 'META'\nAND TRADE_TIME BETWEEN '2022-10-25 9:30:00' AND '2022-10-25 16:00:00'",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "21bc5b86-d54a-4e12-9665-a1419fac2790",
   "metadata": {
    "name": "bbo_price_md",
    "collapsed": false
   },
   "source": "Second, we can calculate the difference between our trade price vs the BBO price that is closest to our trade time, as well as the difference of the BBO price 1000 ms later."
  },
  {
   "cell_type": "code",
   "id": "ea835411-f561-4a20-98b7-2f9322584fd2",
   "metadata": {
    "language": "sql",
    "name": "bbo_price",
    "collapsed": false
   },
   "outputs": [],
   "source": "WITH q AS (\n    SELECT\n        TIMESTAMP_FROM_PARTS(\n            SUBSTR(date, 0, 4),            -- year\n            SUBSTR(date, 5, 2),            -- month\n            SUBSTR(date, 7, 2),            -- day\n            SUBSTR(LPAD(time, 9, 0), 0, 2), -- hour\n            SUBSTR(LPAD(time, 9, 0), 3, 2), -- minute\n            SUBSTR(LPAD(time, 9, 0), 5, 2), -- second\n            RPAD(SUBSTR(LPAD(time, 9, 0), 7, 3), 9, 0) -- nanoseconds\n        ) AS trade_timestamp,\n        *\n    FROM tick_history.public.th_sf_mktplace \n    WHERE ticker = 'META'\n    AND trade_timestamp BETWEEN '2022-10-25 09:30:00' AND '2022-10-25 16:30:00'\n    AND msg_type = 15\n)\nSELECT\n    (q.ask + q.bid) / 2 AS mid_price_trade,\n    (qp.ask + qp.bid) / 2 AS mid_price_markout,\n    price AS trade_price,\n    shares AS trade_size\nFROM\n    {{mytrades}} t\n    ASOF JOIN q \n    MATCH_CONDITION (t.trade_time >= q.trade_timestamp) \n    ON t.ticker = q.ticker -- same cardinality\n    ASOF JOIN q qp \n    MATCH_CONDITION (TIMESTAMPADD(ms, 1000, t.trade_time) >= qp.trade_timestamp) \n    ON t.ticker = qp.ticker;",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "8540ed44-6023-4bf3-8dca-85b0a5617a8c",
   "metadata": {
    "name": "markout_val_md",
    "collapsed": false
   },
   "source": "\nFinally we can calculate the markout value, showing us the impact from our trade."
  },
  {
   "cell_type": "code",
   "id": "f31737e5-c187-49ca-9234-c16688622258",
   "metadata": {
    "language": "sql",
    "name": "markout_val",
    "collapsed": false
   },
   "outputs": [],
   "source": "SELECT\n    0::INT AS markout_delay_ms,\n    1e4*SUM(ABS(mid_price_markout-mid_price_trade)*trade_size)/SUM(trade_size*trade_price) AS abs_markout --1e4 basis points\nFROM\n    {{bbo_price}}",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "742f1c32-ae2d-4775-9eff-33de78c01b53",
   "metadata": {
    "collapsed": false,
    "name": "range_between_md"
   },
   "source": "## Use Case 4: Trend Analysis using RANGE-based sliding window\n\nIntraday analysis is valuable for analysts, offering real-time insights into the short-term price movements of a stock. It helps traders and analysts monitor price trends within a time window, aiding in decision-making and strategy development throughout the trading day. This can be easily done using the RANGE-based sliding windows in Snowflake. \n\nNote: A range-based window frame consists of a logically computed set of rows rather than a physical number of rows as would be expressed in a row-based frame. Let's explore Range Between to create interesting time series metrics on our data."
  },
  {
   "cell_type": "markdown",
   "id": "3eca5035-3a68-4ae2-8fa1-4614b0cd5a8f",
   "metadata": {
    "name": "aggregate_md",
    "collapsed": false
   },
   "source": "Instead of calculating the average for every trade timestamp, aggregate the data by regular intervals and then compute the moving average. This approach reduces the granularity of your data."
  },
  {
   "cell_type": "code",
   "id": "63c728b8-7f84-4700-854b-7ee804b4086e",
   "metadata": {
    "language": "sql",
    "name": "aggregated_data",
    "collapsed": false
   },
   "outputs": [],
   "source": "SELECT\n    DATE_TRUNC('minute', trade_timestamp) AS interval_start,\n    ticker,\n    AVG(last_price) AS avg_price,\n    AVG(last_vol) AS avg_vol\nFROM \n    {{meta_trades}}\nWHERE \n    DATE(trade_timestamp) = '2022-06-09'\nGROUP BY\n    DATE_TRUNC('minute', trade_timestamp),\n    ticker",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "44fe07b6-0fb0-4c0e-a59f-f1000b4b1fc1",
   "metadata": {
    "name": "moving_avg_md",
    "collapsed": false
   },
   "source": "This query calculates the 10-minute moving average of the last_price for META trades throughout the trading day on June 9, 2022. \nA range-based [window frame](https://docs.snowflake.com/en/sql-reference/functions-analytic) consists of a logically computed set of rows rather than a physical number of rows as would be expressed in a row-based frame. Let's explore Range Between to create interesting time series metrics on our data."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43cefc7-91e7-4fa2-8ac3-897c3d21d661",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "sql",
    "name": "moving_avg"
   },
   "outputs": [],
   "source": "SELECT\n    interval_start AS trade_timestamp,\n    ticker,\n    AVG(avg_price) OVER (\n        PARTITION BY ticker\n        ORDER BY interval_start \n        RANGE BETWEEN INTERVAL '10 MINUTE' PRECEDING AND CURRENT ROW\n    ) AS moving_avg\nFROM \n    {{aggregated_data}};"
  },
  {
   "cell_type": "markdown",
   "id": "7fc02c50-b51d-46c8-9912-046266dd4d88",
   "metadata": {
    "collapsed": false,
    "name": "volume_weighted_md"
   },
   "source": "This query calculates the volume-weighted average price  (VWAP) for each ticker over a rolling 10-minute window throughout the trading day on June 9, 2022. VWAP is a key metric used by traders and analysts to understand the average price at which a stock has traded, weighted by the volume of trades. It provides a more accurate reflection of the stock’s price level considering the size of each trade"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0cca993-7f76-4d1a-ae85-907ab62e02ff",
   "metadata": {
    "collapsed": false,
    "language": "sql",
    "name": "volume_weighted"
   },
   "outputs": [],
   "source": "SELECT \n    ticker,\n    interval_start AS trade_timestamp,\n    avg_price,\n    avg_vol,\n    SUM(avg_price * avg_vol) OVER (\n        PARTITION BY ticker \n        ORDER BY trade_timestamp \n        RANGE BETWEEN INTERVAL '10 MINUTE' PRECEDING AND CURRENT ROW\n    ) / \n    SUM(avg_vol) OVER (\n        PARTITION BY ticker \n        ORDER BY trade_timestamp \n        RANGE BETWEEN INTERVAL '10 MINUTE' PRECEDING AND CURRENT ROW\n    ) AS volume_weighted_avg\nFROM {{aggregated_data}};"
  },
  {
   "cell_type": "markdown",
   "id": "8c6d53de-0b59-48e5-ab85-a1e67b77e2e7",
   "metadata": {
    "name": "time_weighted_avg_md",
    "collapsed": false
   },
   "source": "This query calculates the time-weighted average price (TWAP) for each ticker over a rolling 10-minute window throughout the trading day on June 9, 2022. TWAP measures the average price of a stock weighted by the duration each price level was active. It provides a more accurate representation of the stock’s price level by considering the time each price was held, helping traders and analysts understand price trends over time."
  },
  {
   "cell_type": "code",
   "id": "2750d762-ff81-4154-b05e-53ce3b7ba730",
   "metadata": {
    "language": "sql",
    "name": "time_weighted_avg",
    "collapsed": false
   },
   "outputs": [],
   "source": "WITH trade_durations AS (\n    SELECT\n        ticker,\n        interval_start AS trade_timestamp,\n        avg_price,\n        avg_vol,\n        LAG(trade_timestamp) OVER (\n            PARTITION BY ticker \n            ORDER BY trade_timestamp\n        ) AS prev_trade_timestamp\n    FROM {{aggregated_data}}\n),\nprice_weighted AS (\n    SELECT\n        ticker,\n        trade_timestamp,\n        avg_price,\n        avg_vol,\n        CASE\n            WHEN prev_trade_timestamp IS NULL THEN 0\n            ELSE DATEDIFF(SECOND, prev_trade_timestamp, trade_timestamp)\n        END AS duration_seconds\n    FROM trade_durations\n),\ntime_weighted_avg AS (\n    SELECT\n        ticker,\n        trade_timestamp,\n        CASE\n            WHEN SUM(duration_seconds) OVER (\n                PARTITION BY ticker \n                ORDER BY trade_timestamp \n                RANGE BETWEEN INTERVAL '10 MINUTE' PRECEDING AND CURRENT ROW\n            ) = 0 THEN 0\n            ELSE SUM(avg_price * duration_seconds) OVER (\n                PARTITION BY ticker \n                ORDER BY trade_timestamp \n                RANGE BETWEEN INTERVAL '10 MINUTE' PRECEDING AND CURRENT ROW\n            ) / \n            SUM(duration_seconds) OVER (\n                PARTITION BY ticker \n                ORDER BY trade_timestamp \n                RANGE BETWEEN INTERVAL '10 MINUTE' PRECEDING AND CURRENT ROW\n            )\n        END AS time_weighted_avg\n    FROM price_weighted\n)\nSELECT\n    ticker,\n    trade_timestamp,\n    time_weighted_avg\nFROM time_weighted_avg\nWHERE time_weighted_avg != 0;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a99d3e2d-3eb2-43ed-8f57-5168a918ce6e",
   "metadata": {
    "language": "python",
    "name": "comparision",
    "collapsed": false
   },
   "outputs": [],
   "source": "import matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas as pd\n\ndf_moving_avg = moving_avg.to_pandas()\ndf_vwap = volume_weighted.to_pandas()\ndf_time_weighted_avg = time_weighted_avg.to_pandas()\ndf_combined = pd.merge(df_moving_avg, df_vwap, on=['TRADE_TIMESTAMP', 'TICKER'], how='outer')\ndf_combined = pd.merge(df_combined, df_time_weighted_avg, on=['TRADE_TIMESTAMP', 'TICKER'], how='outer')\n\n# Ensure no duplicate columns\ndf_combined = df_combined[['TRADE_TIMESTAMP', 'MOVING_AVG', 'VOLUME_WEIGHTED_AVG', 'TIME_WEIGHTED_AVG']]\ndf_combined",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a77372d9-87e6-4fd2-8bbb-14ca2f0b369f",
   "metadata": {
    "language": "python",
    "name": "plot_comparision",
    "collapsed": false
   },
   "outputs": [],
   "source": "plt.figure(figsize=(14, 7))\n\n# Plot Moving Average\nsns.lineplot(x='TRADE_TIMESTAMP', y='MOVING_AVG', data=df_combined, label='Moving Average', color='green')\n\n# Plot VWAP\nsns.lineplot(x='TRADE_TIMESTAMP', y='VOLUME_WEIGHTED_AVG', data=df_combined, label='VOLUME_WEIGHTED_AVG', color='blue')\n\n# Plot TWAP\nsns.lineplot(x='TRADE_TIMESTAMP', y='TIME_WEIGHTED_AVG', data=df_combined, label='TIME_WEIGHTED_AVG', color='red')\n\nplt.xlabel('Date')\nplt.ylabel('Price')\nplt.title('Moving Average, VWAP, and TWAP Over Time')\nplt.legend()\nplt.show()",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "92aaa778-c14a-4781-9110-62285440921e",
   "metadata": {
    "name": "findings_comparision_md",
    "collapsed": false
   },
   "source": "As the plot shows, the moving averages, VWAP, and TWAP are behaving consistently, with no significant volatility or divergence in price trends, indicating overall stability for this stock."
  },
  {
   "cell_type": "markdown",
   "id": "8626c781-82c4-4cd6-92f3-3537f6365f03",
   "metadata": {
    "collapsed": false,
    "name": "volatility_assess_md"
   },
   "source": "## Use Case 5: Volatility assessment using LEAD & LAG\n\nThe analysis of price changes between consecutive trades, providing insights into how the price of a stock is evolving throughout the trading day. This query assesses the price of the previous & next trade wrt the current trade using [LEAD](https://docs.snowflake.com/en/sql-reference/functions/lead) & [LAG](https://docs.snowflake.com/en/sql-reference/functions/lag) window functions.  "
  },
  {
   "cell_type": "markdown",
   "id": "b6d1a7d3-6cfa-47a6-87e4-4015307ad177",
   "metadata": {
    "name": "lag_md",
    "collapsed": false
   },
   "source": "We'll start by getting the previous trade price using `LAG`."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effe3d98-0b53-41e0-8e50-b92c1662f50b",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "sql",
    "name": "lag"
   },
   "outputs": [],
   "source": [
    "SELECT \n",
    "    ticker,\n",
    "    trade_timestamp,\n",
    "    last_price,\n",
    "    LAG(last_price, 1) OVER (\n",
    "        PARTITION BY ticker \n",
    "        ORDER BY trade_timestamp\n",
    "    ) AS previous_price\n",
    "FROM {{meta_trades}}\n",
    "WHERE DATE(trade_timestamp) = '2022-06-09'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4db120-95ed-4925-b8f7-a9531174614f",
   "metadata": {
    "collapsed": false,
    "name": "lead_md"
   },
   "source": "We'll now use `LEAD` to get the next immediate trade. "
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0dfae6c-c0da-4a14-bb88-a9324b0b0cf8",
   "metadata": {
    "collapsed": false,
    "language": "sql",
    "name": "lead"
   },
   "outputs": [],
   "source": [
    "SELECT \n",
    "    ticker,\n",
    "    trade_timestamp,\n",
    "    last_price,\n",
    "    LEAD(last_price, 1) OVER (\n",
    "        PARTITION BY ticker \n",
    "        ORDER BY trade_timestamp\n",
    "    ) AS next_price\n",
    "FROM {{meta_trades}}\n",
    "WHERE DATE(trade_timestamp) = '2022-06-09'"
   ]
  }
 ]
}